function [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
% [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
% 훈련된 분류기와 그 정확도을(를) 반환합니다. 이 코드는 분류 학습기 앱에서 훈련된 분류
% 모델을 다시 만듭니다. 생성된 코드를 사용하여 동일한 모델을 새 데이터로 훈련시키는 것을
% 자동화하거나, 모델을 프로그래밍 방식으로 훈련시키는 방법을 익힐 수 있습니다.
%
%  입력값:
%      trainingData: 앱으로 가져온 행렬과 동일한 개수의 열과 데이터형을 갖는 행렬입니
%       다.
%
%  출력값:
%      trainedClassifier: 훈련된 분류기가 포함된 구조체입니다. 이 구조체에는 훈련된
%       분류기에 대한 정보가 포함된 다양한 필드가 들어 있습니다.
%
%      trainedClassifier.predictFcn: 새 데이터를 사용하여 예측하기 위한 함수입니
%       다.
%
%      validationAccuracy: 정확도(%)를 포함하는 double형입니다. 이 전반적인 정확도
%       점수는 앱의 내역 목록에 각 모델별로 표시됩니다.
%
% 새 데이터로 모델을 훈련시키려면 이 코드를 사용하십시오. 분류기를 다시 훈련시키려면 명령
% 줄에서 원래 데이터나 새 데이터를 입력 인수 trainingData(으)로 사용하여 함수를 호출하
% 십시오.
%
% 예를 들어, 원래 데이터 세트 T(으)로 훈련된 분류기를 다시 훈련시키려면 다음을 입력하십
% 시오.
%   [trainedClassifier, validationAccuracy] = trainClassifier(T)
%
% 새 데이터 T2에서 반환된 'trainedClassifier'을(를) 사용하여 예측하려면 다음을 사용
% 하십시오.
%   yfit = trainedClassifier.predictFcn(T2)
%
% T2은(는) 훈련에 사용된 예측 변수 열만 포함하는 행렬이어야 합니다. 세부 정보를 보려면
% 다음을 입력하십시오.
%   trainedClassifier.HowToPredict

% MATLAB에서 2022-05-16 21:50:32에 자동 생성됨


% 예측 변수와 응답 변수 추출
% 이 코드는 모델을 훈련시키기에 적합한 형태로 데이터를
% 처리합니다.
% 입력값을 테이블로 변환
inputTable = array2table(trainingData, 'VariableNames', {'column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6', 'column_7', 'column_8', 'column_9', 'column_10', 'column_11', 'column_12', 'column_13', 'column_14', 'column_15', 'column_16', 'column_17', 'column_18', 'column_19', 'column_20', 'column_21', 'column_22', 'column_23', 'column_24', 'column_25', 'column_26', 'column_27', 'column_28', 'column_29'});

predictorNames = {'column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6', 'column_7', 'column_8', 'column_9', 'column_10', 'column_11', 'column_12', 'column_13', 'column_14', 'column_15', 'column_16', 'column_17', 'column_18', 'column_19', 'column_20', 'column_21', 'column_22', 'column_23', 'column_24', 'column_25', 'column_26', 'column_27', 'column_28'};
predictors = inputTable(:, predictorNames);
response = inputTable.column_29;
isCategoricalPredictor = [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false];

% 예측 변수 행렬에 PCA를 적용합니다.
% 숫자형 예측 변수에 대해서만 PCA를 실행합니다. categorical형 예측 변수는 PCA를 거쳐도 전혀 변경되지 않습니다.
isCategoricalPredictorBeforePCA = isCategoricalPredictor;
numericPredictors = predictors(:, ~isCategoricalPredictor);
numericPredictors = table2array(varfun(@double, numericPredictors));
% PCA의 경우 'inf' 값은 누락된 데이터로 처리되어야 합니다.
numericPredictors(isinf(numericPredictors)) = NaN;
[pcaCoefficients, pcaScores, ~, ~, explained, pcaCenters] = pca(...
    numericPredictors);
% 원하는 크기의 분산을 설명하기에 충분한 성분 개수를 유지합니다.
explainedVarianceToKeepAsFraction = 95/100;
numComponentsToKeep = find(cumsum(explained)/sum(explained) >= explainedVarianceToKeepAsFraction, 1);
pcaCoefficients = pcaCoefficients(:,1:numComponentsToKeep);
predictors = [array2table(pcaScores(:,1:numComponentsToKeep)), predictors(:, isCategoricalPredictor)];
isCategoricalPredictor = [false(1,numComponentsToKeep), true(1,sum(isCategoricalPredictor))];

% 분류기 훈련
% 이 코드는 모든 분류기 옵션을 지정하고 분류기를 훈련시킵니다.
template = templateSVM(...
    'KernelFunction', 'gaussian', ...
    'PolynomialOrder', [], ...
    'KernelScale', 2.384323557430819, ...
    'BoxConstraint', 26.01981829261758, ...
    'Standardize', true);
classificationSVM = fitcecoc(...
    predictors, ...
    response, ...
    'Learners', template, ...
    'Coding', 'onevsall', ...
    'ClassNames', [0; 1; 2; 3; 4; 5; 6]);

% 예측 함수를 사용하여 결과 구조체 생성
predictorExtractionFcn = @(x) array2table(x, 'VariableNames', predictorNames);
pcaTransformationFcn = @(x) [ array2table((table2array(varfun(@double, x(:, ~isCategoricalPredictorBeforePCA))) - pcaCenters) * pcaCoefficients), x(:,isCategoricalPredictorBeforePCA) ];
svmPredictFcn = @(x) predict(classificationSVM, x);
trainedClassifier.predictFcn = @(x) svmPredictFcn(pcaTransformationFcn(predictorExtractionFcn(x)));

% 추가적인 필드를 결과 구조체에 추가
trainedClassifier.PCACenters = pcaCenters;
trainedClassifier.PCACoefficients = pcaCoefficients;
trainedClassifier.ClassificationSVM = classificationSVM;
trainedClassifier.About = '이 구조체는 분류 학습기 R2020a에서 내보낸 훈련된 모델입니다.';
trainedClassifier.HowToPredict = sprintf('새 예측 변수 열 행렬 X를 사용하여 예측하려면 다음을 사용하십시오. \n yfit = c.predictFcn(X) \n여기서 ''c''를 이 구조체를 나타내는 변수의 이름(예: ''trainedModel'')으로 바꾸십시오. \n \n이 모델은 28개의 예측 변수를 사용하여 훈련되었으므로 X는 정확히 28개의 열을 포함해야 합니다. \nX는 훈련 데이터와 정확히 동일한 순서와 형식의 예측 변수 열만 포함해야 \n합니다. 응답 변수 열이나 앱으로 가져오지 않은 열은 포함시키지 마십시오. \n \n자세한 내용은 <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>을(를) 참조하십시오.');

% 예측 변수와 응답 변수 추출
% 이 코드는 모델을 훈련시키기에 적합한 형태로 데이터를
% 처리합니다.
% 입력값을 테이블로 변환
inputTable = array2table(trainingData, 'VariableNames', {'column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6', 'column_7', 'column_8', 'column_9', 'column_10', 'column_11', 'column_12', 'column_13', 'column_14', 'column_15', 'column_16', 'column_17', 'column_18', 'column_19', 'column_20', 'column_21', 'column_22', 'column_23', 'column_24', 'column_25', 'column_26', 'column_27', 'column_28', 'column_29'});

predictorNames = {'column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6', 'column_7', 'column_8', 'column_9', 'column_10', 'column_11', 'column_12', 'column_13', 'column_14', 'column_15', 'column_16', 'column_17', 'column_18', 'column_19', 'column_20', 'column_21', 'column_22', 'column_23', 'column_24', 'column_25', 'column_26', 'column_27', 'column_28'};
predictors = inputTable(:, predictorNames);
response = inputTable.column_29;
isCategoricalPredictor = [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false];

% 교차 검증 수행
KFolds = 10;
cvp = cvpartition(response, 'KFold', KFolds);
% 예측값을 적절한 크기로 초기화
validationPredictions = response;
numObservations = size(predictors, 1);
numClasses = 7;
validationScores = NaN(numObservations, numClasses);
for fold = 1:KFolds
    trainingPredictors = predictors(cvp.training(fold), :);
    trainingResponse = response(cvp.training(fold), :);
    foldIsCategoricalPredictor = isCategoricalPredictor;
    
    % 예측 변수 행렬에 PCA를 적용합니다.
    % 숫자형 예측 변수에 대해서만 PCA를 실행합니다. categorical형 예측 변수는 PCA를 거쳐도 전혀 변경되지 않습니다.
    isCategoricalPredictorBeforePCA = foldIsCategoricalPredictor;
    numericPredictors = trainingPredictors(:, ~foldIsCategoricalPredictor);
    numericPredictors = table2array(varfun(@double, numericPredictors));
    % PCA의 경우 'inf' 값은 누락된 데이터로 처리되어야 합니다.
    numericPredictors(isinf(numericPredictors)) = NaN;
    [pcaCoefficients, pcaScores, ~, ~, explained, pcaCenters] = pca(...
        numericPredictors);
    % 원하는 크기의 분산을 설명하기에 충분한 성분 개수를 유지합니다.
    explainedVarianceToKeepAsFraction = 95/100;
    numComponentsToKeep = find(cumsum(explained)/sum(explained) >= explainedVarianceToKeepAsFraction, 1);
    pcaCoefficients = pcaCoefficients(:,1:numComponentsToKeep);
    trainingPredictors = [array2table(pcaScores(:,1:numComponentsToKeep)), trainingPredictors(:, foldIsCategoricalPredictor)];
    foldIsCategoricalPredictor = [false(1,numComponentsToKeep), true(1,sum(foldIsCategoricalPredictor))];
    
    % 분류기 훈련
    % 이 코드는 모든 분류기 옵션을 지정하고 분류기를 훈련시킵니다.
    template = templateSVM(...
        'KernelFunction', 'gaussian', ...
        'PolynomialOrder', [], ...
        'KernelScale', 2.384323557430819, ...
        'BoxConstraint', 26.01981829261758, ...
        'Standardize', true);
    classificationSVM = fitcecoc(...
        trainingPredictors, ...
        trainingResponse, ...
        'Learners', template, ...
        'Coding', 'onevsall', ...
        'ClassNames', [0; 1; 2; 3; 4; 5; 6]);
    
    % 예측 함수를 사용하여 결과 구조체 생성
    pcaTransformationFcn = @(x) [ array2table((table2array(varfun(@double, x(:, ~isCategoricalPredictorBeforePCA))) - pcaCenters) * pcaCoefficients), x(:,isCategoricalPredictorBeforePCA) ];
    svmPredictFcn = @(x) predict(classificationSVM, x);
    validationPredictFcn = @(x) svmPredictFcn(pcaTransformationFcn(x));
    
    % 추가적인 필드를 결과 구조체에 추가
    
    % 검증 예측값 계산
    validationPredictors = predictors(cvp.test(fold), :);
    [foldPredictions, foldScores] = validationPredictFcn(validationPredictors);
    
    % 예측값을 원래 순서대로 저장
    validationPredictions(cvp.test(fold), :) = foldPredictions;
    validationScores(cvp.test(fold), :) = foldScores;
end

% 검증 정확도 계산
correctPredictions = (validationPredictions == response);
isMissing = isnan(response);
correctPredictions = correctPredictions(~isMissing);
validationAccuracy = sum(correctPredictions)/length(correctPredictions);
